{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31155,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# Toy Transformer using JAX + Flax on AG News\n# ============================================================\n\n!pip install -q flax optax datasets tensorboard\n\n# ============================================================\n# 0. GPU preference + bfloat16 global policy\n# ============================================================\nimport os\nos.environ[\"JAX_PLATFORM_NAME\"] = \"gpu\"\n\nimport jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom flax.training import train_state\nimport optax\nfrom datasets import load_dataset\nfrom torch.utils.tensorboard import SummaryWriter\nimport numpy as np\n\n# Check available backend\nprint(\"JAX default backend:\", jax.default_backend())\nprint(\"Available devices:\", jax.devices())\n\n# ============================================================\n# 1. Enable bfloat16 precision (optional fallback to float32)\n# ============================================================\nif any(d.device_kind == \"TPU\" or \"P100\" in d.device_kind for d in jax.devices()):\n    dtype = jnp.bfloat16\n    print(\" Using bfloat16 precision\")\nelse:\n    dtype = jnp.float32\n    print(\"Using float32 (fallback, GPU/CPU without bfloat16 support)\")\n\n# ============================================================\n# 2. Dataset (AG News small subset)\n# ============================================================\nkey = jax.random.PRNGKey(42)\ndataset = load_dataset(\"ag_news\")\ntrain_data = dataset[\"train\"].shuffle(seed=0).select(range(500))\ntest_data = dataset[\"test\"].select(range(200))\n\ndef tokenize(text):\n    return text.lower().split()\n\nvocab = {}\ndef encode(text, max_len=32):\n    tokens = tokenize(text)\n    ids = []\n    for t in tokens:\n        if t not in vocab:\n            vocab[t] = len(vocab) + 1\n        ids.append(vocab[t])\n    ids = ids[:max_len]\n    arr = np.array(ids + [0]*(max_len - len(ids)))\n    return arr\n\nX_train = np.stack([encode(x[\"text\"]) for x in train_data])\ny_train = np.array([x[\"label\"] for x in train_data])\nX_test = np.stack([encode(x[\"text\"]) for x in test_data])\ny_test = np.array([x[\"label\"] for x in test_data])\n\nvocab_size = len(vocab) + 1\nnum_classes = 4\nmax_len = X_train.shape[1]\n\n# ============================================================\n# 3. Transformer Encoder (bfloat16 support)\n# ============================================================\nclass PositionalEncoding(nn.Module):\n    emb_dim: int\n    max_len: int\n    dtype: any\n\n    @nn.compact\n    def __call__(self, x):\n        pos = jnp.arange(self.max_len)[:, None]\n        i = jnp.arange(self.emb_dim)[None, :]\n        angle_rates = 1 / jnp.power(10000, (2 * (i//2)) / self.emb_dim)\n        angle_rads = pos * angle_rates\n        pos_encoding = jnp.where(i % 2 == 0,\n                                 jnp.sin(angle_rads),\n                                 jnp.cos(angle_rads))\n        pos_encoding = pos_encoding[jnp.newaxis, :, :].astype(self.dtype)\n        return x + pos_encoding[:, :x.shape[1], :]\n\nclass FeedForward(nn.Module):\n    emb_dim: int\n    hidden_dim: int\n    dtype: any\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.Dense(self.hidden_dim, dtype=self.dtype)(x)\n        x = nn.relu(x)\n        x = nn.Dense(self.emb_dim, dtype=self.dtype)(x)\n        return x\n\nclass TransformerBlock(nn.Module):\n    emb_dim: int\n    num_heads: int\n    ff_dim: int\n    dtype: any\n\n    @nn.compact\n    def __call__(self, x):\n        attn_out = nn.MultiHeadDotProductAttention(\n            num_heads=self.num_heads,\n            dtype=self.dtype\n        )(x, x)\n        x = nn.LayerNorm(dtype=self.dtype)(x + attn_out)\n\n        ff_out = FeedForward(self.emb_dim, self.ff_dim, self.dtype)(x)\n        x = nn.LayerNorm(dtype=self.dtype)(x + ff_out)\n        return x\n\nclass TransformerEncoder(nn.Module):\n    vocab_size: int\n    max_len: int\n    emb_dim: int = 64\n    num_heads: int = 4\n    ff_dim: int = 128\n    num_layers: int = 2\n    num_classes: int = 4\n    dtype: any = jnp.float32\n\n    @nn.compact\n    def __call__(self, x):\n        # Embedding + positional encoding\n        x = nn.Embed(self.vocab_size, self.emb_dim, dtype=self.dtype)(x)\n        x = PositionalEncoding(self.emb_dim, self.max_len, self.dtype)(x)\n\n        for _ in range(self.num_layers):\n            x = TransformerBlock(self.emb_dim, self.num_heads, self.ff_dim, self.dtype)(x)\n\n        x = jnp.mean(x, axis=1)\n        x = nn.Dense(self.num_classes, dtype=jnp.float32)(x)  # logits in float32\n        return x\n\n# ============================================================\n# 4. Initialize model & optimizer\n# ============================================================\nmodel = TransformerEncoder(vocab_size=vocab_size, max_len=max_len, dtype=dtype)\nparams = model.init(key, jnp.ones((1, max_len), dtype=jnp.int32))\ntx = optax.adam(1e-3)\n\nstate = train_state.TrainState.create(\n    apply_fn=model.apply,\n    params=params,\n    tx=tx\n)\n\n# ============================================================\n# 5. Training functions\n# ============================================================\ndef cross_entropy_loss(params, batch):\n    logits = state.apply_fn(params, batch[\"inputs\"])\n    one_hot = jax.nn.one_hot(batch[\"labels\"], num_classes=num_classes)\n    return optax.softmax_cross_entropy(logits, one_hot).mean()\n\n@jax.jit\ndef train_step(state, batch):\n    grads = jax.grad(cross_entropy_loss)(state.params, batch)\n    return state.apply_gradients(grads=grads)\n\n@jax.jit\ndef compute_accuracy(params, batch):\n    preds = jnp.argmax(state.apply_fn(params, batch[\"inputs\"]), axis=-1)\n    return jnp.mean(preds == batch[\"labels\"])\n\n# ============================================================\n# 6. TensorBoard setup\n# ============================================================\nwriter = SummaryWriter(\"runs/jax_bfloat16_transformer\")\n\n# ============================================================\n# 7. Training loop\n# ============================================================\nfor epoch in range(50):\n    batch = {\n        \"inputs\": jax.device_put(jnp.array(X_train, dtype=jnp.int32)),\n        \"labels\": jax.device_put(jnp.array(y_train))\n    }\n\n    state = train_step(state, batch)\n    loss = cross_entropy_loss(state.params, batch)\n    acc = compute_accuracy(state.params, batch)\n\n    writer.add_scalar(\"Loss/train\", float(loss), epoch)\n    writer.add_scalar(\"Accuracy/train\", float(acc), epoch)\n\n    print(f\"Epoch {epoch+1}: Loss={loss:.4f}, Accuracy={acc*100:.2f}%\")\n\nwriter.close()\nprint(\"Training complete — visualize with TensorBoard!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T18:01:11.284143Z","iopub.execute_input":"2025-10-09T18:01:11.284376Z","iopub.status.idle":"2025-10-09T18:02:01.556879Z","shell.execute_reply.started":"2025-10-09T18:01:11.284353Z","shell.execute_reply":"2025-10-09T18:02:01.556147Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"2025-10-09 18:01:29.781306: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760032889.968786      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760032890.026787      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO:2025-10-09 18:01:39,351:jax._src.xla_bridge:924: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\nINFO:2025-10-09 18:01:39,363:jax._src.xla_bridge:924: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n","output_type":"stream"},{"name":"stdout","text":"JAX default backend: gpu\nAvailable devices: [CudaDevice(id=0)]\n Using bfloat16 precision\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b4e991692c24997854ff2daedb1eab0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e980e0a9db874243baf70482eeb391ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6aa367eb731f4d42b9c12904b8f7a99c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86160a96176340ba98cf042db116f063"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35fb950f81b64b628f614d48d4f98288"}},"metadata":{}},{"name":"stdout","text":"Epoch 1: Loss=1.4297, Accuracy=29.00%\nEpoch 2: Loss=1.5390, Accuracy=22.00%\nEpoch 3: Loss=1.4309, Accuracy=22.00%\nEpoch 4: Loss=1.3730, Accuracy=23.20%\nEpoch 5: Loss=1.4010, Accuracy=29.20%\nEpoch 6: Loss=1.4179, Accuracy=29.00%\nEpoch 7: Loss=1.3968, Accuracy=29.00%\nEpoch 8: Loss=1.3815, Accuracy=39.80%\nEpoch 9: Loss=1.3763, Accuracy=25.80%\nEpoch 10: Loss=1.3620, Accuracy=25.80%\nEpoch 11: Loss=1.3478, Accuracy=46.00%\nEpoch 12: Loss=1.3472, Accuracy=40.20%\nEpoch 13: Loss=1.3524, Accuracy=44.20%\nEpoch 14: Loss=1.3503, Accuracy=45.00%\nEpoch 15: Loss=1.3395, Accuracy=44.80%\nEpoch 16: Loss=1.3266, Accuracy=55.20%\nEpoch 17: Loss=1.3167, Accuracy=48.60%\nEpoch 18: Loss=1.3085, Accuracy=72.40%\nEpoch 19: Loss=1.2979, Accuracy=54.60%\nEpoch 20: Loss=1.2863, Accuracy=53.40%\nEpoch 21: Loss=1.2770, Accuracy=47.80%\nEpoch 22: Loss=1.2631, Accuracy=47.00%\nEpoch 23: Loss=1.2381, Accuracy=52.40%\nEpoch 24: Loss=1.2105, Accuracy=54.40%\nEpoch 25: Loss=1.1790, Accuracy=55.20%\nEpoch 26: Loss=1.1389, Accuracy=75.00%\nEpoch 27: Loss=1.0983, Accuracy=78.60%\nEpoch 28: Loss=1.0405, Accuracy=91.40%\nEpoch 29: Loss=0.9749, Accuracy=88.20%\nEpoch 30: Loss=0.8973, Accuracy=84.40%\nEpoch 31: Loss=0.8150, Accuracy=77.20%\nEpoch 32: Loss=0.7346, Accuracy=80.00%\nEpoch 33: Loss=0.6538, Accuracy=88.00%\nEpoch 34: Loss=0.6069, Accuracy=86.40%\nEpoch 35: Loss=0.6573, Accuracy=82.80%\nEpoch 36: Loss=0.5037, Accuracy=95.40%\nEpoch 37: Loss=0.4872, Accuracy=94.20%\nEpoch 38: Loss=0.3866, Accuracy=96.20%\nEpoch 39: Loss=0.3724, Accuracy=95.00%\nEpoch 40: Loss=0.2727, Accuracy=98.00%\nEpoch 41: Loss=0.2867, Accuracy=95.60%\nEpoch 42: Loss=0.1811, Accuracy=99.00%\nEpoch 43: Loss=0.1986, Accuracy=97.80%\nEpoch 44: Loss=0.1341, Accuracy=98.80%\nEpoch 45: Loss=0.1074, Accuracy=99.40%\nEpoch 46: Loss=0.1103, Accuracy=99.40%\nEpoch 47: Loss=0.0786, Accuracy=99.40%\nEpoch 48: Loss=0.0583, Accuracy=99.60%\nEpoch 49: Loss=0.0572, Accuracy=99.60%\nEpoch 50: Loss=0.0526, Accuracy=99.60%\nTraining complete — visualize with TensorBoard!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from tensorboard import notebook\n\nnotebook.start(\"--logdir runs/jax_bfloat16_transformer\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T18:06:44.226236Z","iopub.execute_input":"2025-10-09T18:06:44.226948Z","iopub.status.idle":"2025-10-09T18:06:51.265891Z","shell.execute_reply.started":"2025-10-09T18:06:44.226920Z","shell.execute_reply":"2025-10-09T18:06:51.265096Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    "},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import os\nprint(os.listdir(\"runs/jax_bfloat16_transformer\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T18:07:06.566898Z","iopub.execute_input":"2025-10-09T18:07:06.567414Z","iopub.status.idle":"2025-10-09T18:07:06.571724Z","shell.execute_reply.started":"2025-10-09T18:07:06.567388Z","shell.execute_reply":"2025-10-09T18:07:06.570838Z"}},"outputs":[{"name":"stdout","text":"['events.out.tfevents.1760032910.420c89ce379d.37.0']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}